"""
Script to run clustering analysis on video clips.
Configured via internal SETTINGS dictionary.
"""
import json
import sys
import logging
from pathlib import Path
from datetime import datetime

# Ensure src is in pythonpath
sys.path.append(str(Path(__file__).parent.parent / "src"))

from vidsynth.core.datamodels import Clip
from vidsynth.core.config import load_config
from vidsynth.cluster import ClusterEngine, ClusterVideoComposer

# --- SETTINGS ---
SETTINGS = {
    # Path to the clips.json generated by Step 1
    "input_clips_json": "output/clips_Summer_vacation.mp4.json",
    
    # Path to the source video file used in Step 1
    # NOTE: Update this to match your actual video file path if different
    "source_video_path": "assets/raw/Summer_vacation.mp4", 
    
    # Output directory for clustering results
    "output_dir": "output/clusters/Summer_vacation",
    
    # Clustering parameters
    "max_clusters": 5,
    "top_k_representatives": 7,
    
    # Config path (optional, defaults to standard locations)
    "config_path": "configs/baseline.yaml" 
}

def main():
    # Setup logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger("cluster_analysis")

    # 1. Load Config & Dependencies
    input_path = Path(SETTINGS["input_clips_json"])
    source_video = Path(SETTINGS["source_video_path"])
    output_dir = Path(SETTINGS["output_dir"])
    
    if not input_path.exists():
        logger.error(f"Clips JSON not found at: {input_path}")
        return
    
    if not source_video.exists():
        # Warning instead of error, as we might just want JSON analysis if video is missing
        logger.warning(f"Source video not found at: {source_video}. Video generation will fail.")
    
    pipeline_config = load_config(Path(SETTINGS["config_path"])) if Path(SETTINGS["config_path"]).exists() else load_config()

    # 2. Load Clips
    logger.info(f"Loading clips from {input_path}...")
    with open(input_path, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
        clips = [Clip.from_dict(item) for item in raw_data]
    
    logger.info(f"Loaded {len(clips)} clips.")

    # 3. Perform Clustering
    logger.info("Running K-Means clustering...")
    engine = ClusterEngine()
    results = engine.perform_clustering(
        clips, 
        max_clusters=SETTINGS["max_clusters"],
        representative_count=SETTINGS["top_k_representatives"]
    )
    
    logger.info(f"Identified {len(results)} clusters.")

    # 4. Export Analysis JSON
    output_dir.mkdir(parents=True, exist_ok=True)
    analysis_data = {
        "meta": {
            "timestamp": datetime.now().isoformat(),
            "source_clips": str(input_path),
            "parameters": SETTINGS
        },
        "clusters": [r.to_dict() for r in results]
    }
    
    json_path = output_dir / "analysis.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(analysis_data, f, indent=2, ensure_ascii=False)
    logger.info(f"Clustering analysis saved to {json_path}")

    # 5. Generate Videos
    if source_video.exists():
        logger.info("Generating representative videos for clusters...")
        composer = ClusterVideoComposer(pipeline_config)
        try:
            video_paths = composer.compose_all(results, source_video, output_dir)
            logger.info(f"Generated {len(video_paths)} cluster videos in {output_dir}")
        except Exception as e:
            logger.error(f"Error during video composition: {e}")
    else:
        logger.warning("Skipping video generation (source video missing).")

if __name__ == "__main__":
    main()
